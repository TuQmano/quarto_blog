---
title: "argendata: El camino de los datos" 
subtitle: "C√≥mo se construye una infraestructura de datos abiertos con foco en evidencia, reproducibilidad y colaboraci√≥n"
author: Juan Pablo Ruiz Nicolini
date: '2025-07-22'
slug: argendata1
categories: [argendata, data, fundar]
tags: [argendata, data, fundar]
---

# argendata: un a√±o

En este, nuestro primer cumplea√±itos, quiero compartir un poco m√°s de detalle del **laburo datero** que hay por detr√°s de este peque√±o gran orgullo TuQmano. Y extender un agradecimiento por el enorme esfuerzo a todo **fundar,** pero en particular a "los datasets", el equipo que lider√≥ el trabajo que ac√° comparto y a nuestra capitana Pau Isaak.\


```{r} 
#| label: fig-collage 
#| echo: false 
#| layout-ncol: 3 
#| fig-cap: "Un a√±o de datos en Argendata" 
#| fig-subcap: 
#|    - "El lanzamiento" 
#|    - "Sprint final" 
#|    - "El triunvirato"
#|    - "Contando nuestra experiencia en Exactas (UBA)" 
#|    - "Un d√≠a m√°s de sripting" 
#|    - "Agotados, pero felices" 

knitr::include_graphics(c(   
  "data/argendata-lunch.jpeg",  
  "data/argendata-sprint.jpeg",   
  "data/argendata.jpeg",  
  "data/argendata_tks.jpeg",  
  "data/datasets1.jpeg",   
  "data/datasets2.jpeg" ))


```

## üß± *Dise√±ar para durar: los fundamentos t√©cnicos de Argendata*

### ¬øQu√© es Argendata?

[Argendata](https://argendata.fund.ar/) es una iniciativa de [fundar](https://fund.ar/) que busca organizar, armonizar y publicar datos sobre Argentina con una l√≥gica clara: que sirvan para entender mejor, discutir mejor y decidir mejor. En definitiva, un peque√±o aporte que tiene una enorme ambici√≥n: transformar la Argentina.

Pero no se trata solo de subir textos y gr√°ficos. Detr√°s del sitio hay una estructura t√©cnica que permite mantener los datos vivos, trazables y disponibles. Una arquitectura pensada para que el contenido sea m√°s que informaci√≥n: que sea evidencia

------------------------------------------------------------------------

## Los Datos: El Coraz√≥n de Argendata

**TL;DR\
**\
En **Argendata**, la **calidad, transparencia y reproducibilidad de los datos** son fundamentales para nutrir el debate p√∫blico con informaci√≥n confiable. Nuestros procesos est√°n dise√±ados para procurar que cada dato sea robusto y accesible. Nos basamos en **tres pilares** esenciales: la **administraci√≥n de recursos**, que asegura la coherencia y armonizaci√≥n de los datos; un riguroso **control de calidad y reportes**; y la **armonizaci√≥n del c√≥digo fuente**, clave para la reproducibilidad y actualizaci√≥n constante. Este enfoque nos permite transformar los datos generados por investigadores en las visualizaciones claras y √∫tiles que encontr√°s en nuestro sitio.

### Nuestras herramientas clave en el desarrollo de datos

Para lograr todo esto, en Argendata utilizamos un conjunto de **herramientas y repositorios especializados**. Cada uno cumple un rol crucial en el ciclo de vida de nuestros datos, desde la recolecci√≥n y procesamiento hasta la visualizaci√≥n final. A continuaci√≥n, un resumen de estas herramientas:

-   [**`qa`**]: Este repositorio (<https://github.com/argendatafundar/qa>) estructura y simplifica los procesos de creaci√≥n y ejecuci√≥n de controles de calidad sobre los conjuntos de datos. Facilita la administraci√≥n del sistema de archivos y la interacci√≥n para el *Control de Calidad (QA)* entre investigadores y el equipo de datos.

-   [**`geonomencladores`**]: Contiene un diccionario de entidades geogr√°ficas normalizado (<https://github.com/argendatafundar/geonomencladores>) esencial para la consistencia en el uso de datos geogr√°ficos.

-   [**`etl`**]: Este proyecto (<https://github.com/argendatafundar/etl>) se centra en la armonizaci√≥n del proceso de **Exploraci√≥n, Transformaci√≥n y Carga (ETL)** de datos. Su objetivo es reducir la fricci√≥n en la actualizaci√≥n, automatizando pasos como la descarga de fuentes, la limpieza y la generaci√≥n de datasets para visualizaciones.

-   [**`argendataR`**]: Un paquete de `R` (<https://github.com/argendatafundar/argendataR>) que ofrece funciones auxiliares para el proceso ETL, optimizando el flujo de trabajo con fuentes y resultados.

-   [**`data`**]: Aqu√≠ se comparten los datasets definitivos (<https://github.com/argendatafundar/data>), agrupados por t√≥picos y disponibles para descarga directa desde el sitio web de Argendata.

-   [**`data-transformers`**]: Una biblioteca para `Python` (<https://github.com/argendatafundar/data-transformers>) dise√±ada para facilitar la escritura, ejecuci√≥n, reproducibilidad y versionado del c√≥digo fuente que manipula datos estructurados. Su rol principal es formatear los datos para las visualizaciones del *Frontend*.

-   [**`transformers`**]: Este repositorio (<https://github.com/argendatafundar/transformers>) aloja los scripts de `Python` que act√∫an como "recetas" para transformar los datos de `data` al formato requerido por el *Frontend* para la visualizaci√≥n.\
    \
    \
    [![](http://149.50.137.164:2147/static/argendata/argendata-flujo-transparente-negro.svg)](https://github.com/argendatafundar/)

### Sobre nuestros datos

#### Un Vistazo (M√°s) de Cerca a Nuestras Herramientas

#### **`qa`**

El repositorio `qa` (<https://github.com/argendatafundar/qa>) es nuestro caballito de batalla para trabajar por la **calidad y consistencia de los datos**. Tiene dos funciones principales que resultan clave:

1.  **Organizaci√≥n y Administraci√≥n**: `qa` establece una **estructura clara y estandarizada** para el sistema de archivos compartido. Esto es crucial para que todos los investigadores y el equipo de datos trabajen con la misma l√≥gica al guardar y buscar la informaci√≥n, minimizando as√≠ errores y datos duplicados. Asegura que los datos se almacenen de manera predecible, facilitando su gesti√≥n a largo plazo.

2.  **Control de Calidad Interactivo**: Facilita una **colaboraci√≥n constante y efectiva** entre los investigadores, que son quienes generan los datos, y nuestro equipo especializado. A trav√©s de este programa, se realizan **validaciones sistem√°ticas** que permiten detectar inconsistencias, anomal√≠as o errores en etapas tempranas. Por ejemplo, `qa` puede verificar que un campo num√©rico no contenga texto, que los rangos de fechas sean l√≥gicos, o que los valores de una variable categ√≥rica se ajusten a un listado predefinido. Al automatizar estos controles, `qa` acelera el ciclo de desarrollo, reduce la carga de trabajo manual y garantiza que solo los datos m√°s confiables y limpios avancen hacia las siguientes etapas de armonizaci√≥n y visualizaci√≥n. Es, en esencia, nuestro guardi√°n de la integridad de los datos.

#### **`geonomencladores`**

El [geonomenclador](https://github.com/argendatafundar/geonomencladores) es un componente **esencial** en Argendata. Este funciona como un **diccionario estandarizado de entidades geogr√°ficas** (pa√≠ses y regiones). Su prop√≥sito principal es **armonizar datos provenientes de distintas fuentes**, procurando asegurar que todos se refieran a las mismas ubicaciones de manera consistente.

[![](https://github.com/argendatafundar/geonomencladores/raw/main/assets/supervenn.png)](https://github.com/argendatafundar/geonomencladores)

Para construir esta herramienta vital, realizamos un exhaustivo trabajo de **normalizaci√≥n de la nomenclatura de pa√≠ses**. Esto implic√≥ comparar los c√≥digos estandarizados de diversas bases de datos. La priorizaci√≥n de estos c√≥digos se bas√≥ en la proporci√≥n de uso de cada base sobre los datasets de nuestro proyecto, garantizando que el nomenclador refleje las realidades de nuestros datos.

Posteriormente, aplicamos **t√©cnicas de *fuzzy matching*** para unificar los nombres de distintos pa√≠ses y regiones. Este proceso fue importante para resolver variaciones en la escritura o denominaci√≥n de una misma entidad geogr√°fica, como se ilustra en el siguiente gr√°fico, donde cada flecha representa la similitud entre dos regiones basada en sus nombres.

[![](data/geonom_names.png)](https://github.com/argendatafundar/geonomencladores)

#### **`etl`**

El repositorio `etl` (<https://github.com/argendatafundar/etl>) es el **motor que impulsa la generaci√≥n y transformaci√≥n de nuestros datos** de forma program√°tica y reproducible. Contiene los *scripts* en R que garantizan un proceso sistem√°tico de **Extracci√≥n, Transformaci√≥n y Carga (ETL)**.

Este repositorio asegura la **armonizaci√≥n** del flujo de trabajo, lo que reduce la fricci√≥n en cada actualizaci√≥n de datos. Desde la descarga de fuentes *raw* hasta la limpieza y preparaci√≥n de los datasets finales para las visualizaciones, `etl` automatiza pasos cruciales para mantener la coherencia y la eficiencia.

Un aspecto clave de `etl` es su enfoque en la **reproducibilidad**. Todos los *scripts* est√°n dise√±ados para ser modulares y parametrizables, facilitando la colaboraci√≥n entre investigadores y la actualizaci√≥n consistente de la informaci√≥n. Por ejemplo, promovemos el uso de c√≥digo que se adapte autom√°ticamente a cambios en los nombres de columnas a lo largo del tiempo, asegurando que los *scripts* sigan funcionando con nuevas versiones de las fuentes.

Los resultados finales de estos procesos de `etl` se almacenan directamente en el repositorio [`data/`](https://github.com/argendatafundar/data "data"), listos para alimentar las visualizaciones en Argendata.

#### **`argendataR`**

El paquete `argendataR` (<https://github.com/argendatafundar/argendataR>) es una **colecci√≥n de funciones en R** dise√±ada para **simplificar y estandarizar el flujo de trabajo** con las fuentes de datos y los *outputs* generados en el [proceso de armonizaci√≥n (ETL)](https://github.com/argendatafundar/etl/). Este paquete es una herramienta indispensable para investigadores y el equipo de datos, ya que agiliza tareas repetitivas y asegura la consistencia en el manejo de la informaci√≥n.

Por ejemplo, una de sus funcionalidades centrales es la **gesti√≥n de fuentes de datos**, dividida en funciones para fuentes *raw* (originales) y *clean* (procesadas). Permite **registrar y actualizar metadatos** de las fuentes en *Google Sheets*, as√≠ como **cargar y descargar archivos** de *Google Drive*. Por ejemplo, con `agregar_fuente_raw()` y `actualizar_fuente_raw()`, los investigadores pueden gestionar las versiones de los datos brutos, mientras que `agregar_fuente_clean()` y `actualizar_fuente_clean()` se encargan de las versiones ya limpias y preparadas, asegurando que cumplan con los est√°ndares de Argendata (ej., nombres de columnas consistentes, formato *long*).

R

```         
# Ejemplo de c√≥mo se registra una nueva fuente raw por primera vez 

library(argendataR)
## basic example code
agregar_fuente_raw(url = "https://www.ejemplo.com",
                   nombre = "Ejemplo",
                   institucion = "Ejemplo",
                   actualizable = TRUE,
                   fecha_descarga = "2021-01-01",
                   fecha_actualizar = "2022-01-01",
                   path_raw = "ejemplo.csv",
                   script = "ejemplo.R")
```

Adem√°s, `argendataR` es clave en la **generaci√≥n de los *outputs* finales**. Su funci√≥n principal, `write_output()`, es crucial para generar los archivos `.json` con datos y metadatos que Argendata necesita para sus visualizaciones. Opcionalmente, tambi√©n puede exportar un `.csv` siguiendo los est√°ndares de Fundar (UTF-8, delimitadores espec√≠ficos), lo que garantiza la compatibilidad y facilidad de uso de nuestros datasets. Esta funci√≥n encapsula toda la complejidad del formato de salida, permitiendo a los investigadores centrarse en el procesamiento de los datos.

R

```         
# Ejemplo simplificado de uso de write_output para un dataset # df_output ser√≠a el data frame ya procesado y listo 

write_output( data = df_output,
                extension = 'csv',
                output_name = 'A1_inb_pib',
                subtopico = 'ACECON',
                fuentes = 'World Development Indicators',
                analista = 'Andr√©s Salles',
                aclaraciones = NULL,
                exportar = TRUE,
                pk = c("anio", "iso3"),
                es_serie_tiempo = TRUE,
                columna_indice_tiempo = "anio",
                columna_geo_referencia = "iso3",
                nivel_agregacion = "pais",
                nullables = FALSE,
                etiquetas_indicadores = list("diferencia_inb_pbi" = "Diferencia entre Ingreso Bruto Nacional y PBI"),
                unidades = "Porcentaje respecto al PBI",
                classes = NULL)
```

En resumen, `argendataR` es la **caja de herramientas** para el flujo de trabajo de datos en Argendata, promoviendo la **sistematizaci√≥n, la calidad y la eficiencia** en la producci√≥n de conocimiento. Las salidas finales de estos procesos son las que se comparten y actualizan en el repositorio [`data`](https://github.com/argendatafundar/data "data") y alimentan el sitio [argendata.fund.ar](https://argendata.fund.ar/) para la descarga de datos.

#### **`data`**

El repositorio `data` (<https://github.com/argendatafundar/data>) es el **punto central de almacenamiento y distribuci√≥n** de los datasets finales que se publican en Argendata. Estos conjuntos de datos son el resultado del proceso semi-automatizado de **reproducibilidad (ETL)**, lo que asegura su consistencia y calidad. B√°sicamente, `data` es la vidriera donde se consolidan y comparten los datos producidos por los investigadores, listos para su uso y descarga.

##### Organizaci√≥n de los datos

Para mantener la claridad y facilitar el acceso, los datos en este repositorio est√°n meticulosamente organizados:

1.  **Codificaci√≥n por T√≥pico**: Cada t√≥pico de Argendata tiene un **c√≥digo √∫nico de seis letras en may√∫sculas** (ej., `CAMCLI` para "Cambio Clim√°tico", `PRECIO` para "Inflaci√≥n"). Estos c√≥digos sirven como identificadores √∫nicos y estructuran el sistema de archivos del repositorio, agrupando los datasets por su tema principal.

2.  **Archivos por Dataset**: Dentro de la carpeta de cada t√≥pico, se encuentran dos tipos de archivos para cada dataset individual:

    -   El **dataset original limpio** en formato `.csv`. Estos son los datos ya procesados y listos para ser utilizados.

    -   Los **metadatos en formato `.json`**, que acompa√±an a cada dataset con el mismo nombre. Estos archivos `.json` son cruciales porque proveen informaci√≥n detallada sobre el dataset, incluyendo sus fuentes (`fuentes`), tipo de extensi√≥n (`extension`), analistas responsables (`analista`), los **tipos de datos por variable** y otras especificaciones necesarias para su correcta interpretaci√≥n y uso.

    Por ejemplo, el dataset de inflaci√≥n `PRECIO/12_tasa_de_inflacion_mensual_argentina_ene1989_dic1993` viene acompa√±ado de su `.csv` con las columnas `fecha` e `inflacion_mensual`, y un `.json` con sus metadatos (`subtopico`, `output_name`, `extension`, `analista`, `fuentes`). Este esquema garantiza que los usuarios no solo obtengan los datos, sino tambi√©n el contexto y la informaci√≥n necesaria para entenderlos y utilizarlos correctamente.

##### Estructura del sistema de archivos

La organizaci√≥n del repositorio sigue un esquema l√≥gico que refleja la clasificaci√≥n por t√≥pico:

```         
‚îú‚îÄ‚îÄ TOPICO
‚îú‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ CAMCLI
‚îÇ   ‚îú‚îÄ‚îÄ dataset.csv
‚îÇ   ‚îú‚îÄ‚îÄ dataset.json
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ COMEXT
    ‚îú‚îÄ‚îÄ cambio_destinos_exportacion.csv
    ‚îú‚îÄ‚îÄ cambio_destinos_exportacion.json
    ...
```

Esta estructura jer√°rquica facilita la navegaci√≥n y la identificaci√≥n de los conjuntos de datos, permitiendo a los usuarios encontrar r√°pidamente la informaci√≥n de su inter√©s.

Los datos almacenados en este repositorio son los que se disponibilizan directamente para la descarga de los usuarios desde el sitio web de Argendata. Adem√°s, son la base para el procesamiento posterior realizado por el repositorio [`transformers`](https://www.google.com/search?q=%5Bhttps://github.com/argendatafundar/transformers%5D(https://github.com/argendatafundar/transformers)), que los adapta para la visualizaci√≥n interactiva en el *Frontend* de [argendata.fund.ar](https://argendata.fund.ar/).

#### **`data-transformers`**

El repositorio `data-transformers` (<https://github.com/argendatafundar/data-transformers>) es una **biblioteca de `Python`** dise√±ada para ser un componente clave en el **an√°lisis y procesamiento manual-asistido de datos estructurados** dentro de Argendata. Su prop√≥sito principal es **facilitar la escritura, ejecuci√≥n, reproducibilidad y el versionado** del c√≥digo fuente que manipula estos datos.

Esta herramienta se enfoca en el **formato y la preparaci√≥n de los datos** seg√∫n las necesidades espec√≠ficas del c√≥digo utilizado por el *Frontend* para las visualizaciones. No se trata de la generaci√≥n inicial de datos (eso ocurre en `etl`), sino de las transformaciones finales que optimizan los datasets para su presentaci√≥n interactiva. Esto puede incluir tareas como:

-   **Filtrado de valores**: Seleccionar subconjuntos de datos relevantes para una visualizaci√≥n particular.

-   **Selecci√≥n y renombramiento de variables**: Ajustar los nombres de las columnas o seleccionar solo aquellas que son necesarias para el gr√°fico final.

-   **Agregaciones o pivotes espec√≠ficos**: Reestructurar los datos para que se adapten a los requisitos del componente de visualizaci√≥n.

Al centralizar estas transformaciones en `data-transformers`, se garantiza que el paso final de preparaci√≥n de datos sea consistente y que cualquier cambio necesario en el formato de visualizaci√≥n se aplique de manera eficiente y reproducible. Esto es vital para mantener la agilidad en el desarrollo de nuevas visualizaciones y la calidad de la informaci√≥n mostrada en el sitio.

#### **`transformers`**

El repositorio `transformers` (<https://github.com/argendatafundar/transformers>) contiene los **scripts en `Python`** que act√∫an como "recetas" ejecutables y autocontenidas. B√°sicamente, son programas dise√±ados para aplicar una serie de instrucciones de **mutaci√≥n a un dataset**, transform√°ndolo espec√≠ficamente para su visualizaci√≥n en el [sitio web de Argendata](https://argendata.fund.ar).

Estos *scripts* van un paso m√°s all√° de la armonizaci√≥n de datos que se realiza en el proceso [`etl`](https://github.com/argendatafundar/etl). Su objetivo es una **normalizaci√≥n m√°s estricta**, donde se deja √∫nicamente la informaci√≥n imprescindible para que el gr√°fico se pueda visualizar. As√≠, se generan **archivos mucho m√°s livianos y optimizados** para el *Frontend*.

Cada *transformer* se explica por s√≠ mismo en su funcionalidad: describe lo que hace, lo que facilita mucho su comprensi√≥n y garantiza su f√°cil ejecuci√≥n en un proceso automatizado. La relaci√≥n con [`data-transformers`](https://github.com/argendatafundar/data-transformers) es directa: `data-transformers` es la librer√≠a que provee las funciones base que estos *scripts* utilizan para construir sus "recetas".

El trabajo en este repositorio se organiza por **t√≥picos**, reflejando la estructura de Argendata:

```         
‚îú‚îÄ‚îÄ TOPICO
‚îú‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ AGROPE
‚îÇ   ‚îú‚îÄ‚îÄ mappings.json
‚îÇ   ‚îú‚îÄ‚îÄ TOPICO_gXX_transformer.py
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ TRANEN
    ‚îú‚îÄ‚îÄ mappings.json
    ‚îú‚îÄ‚îÄ TRANEN_g01_transformer.py
    ‚îú‚îÄ‚îÄ TRANEN_g02_transformer.py
    ‚îú‚îÄ‚îÄ TRANEN_g03_transformer.py
    ‚îú‚îÄ‚îÄ TRANEN_g04_transformer.py
    ‚îú‚îÄ‚îÄ TRANEN_g05_transformer.py
    ‚îú‚îÄ‚îÄ TRANEN_g06_transformer.py
    ‚îú‚îÄ‚îÄ TRANEN_g07_transformer.py
    ‚îú‚îÄ‚îÄ TRANEN_g08_transformer.py
    ‚îú‚îÄ‚îÄ TRANEN_g09_transformer.py
    ‚îú‚îÄ‚îÄ TRANEN_g10_transformer.py
    ‚îú‚îÄ‚îÄ TRANEN_g11_transformer.py
    ‚îú‚îÄ‚îÄ TRANEN_g12_transformer.py
    ‚îú‚îÄ‚îÄ TRANEN_g13_transformer.py
    ‚îú‚îÄ‚îÄ TRANEN_g14_transformer.py
    ‚îú‚îÄ‚îÄ TRANEN_g15_transformer.py
    ‚îú‚îÄ‚îÄ TRANEN_g16_transformer.py
    ‚îú‚îÄ‚îÄ TRANEN_g17_transformer.py
    ‚îú‚îÄ‚îÄ TRANEN_g18_transformer.py
    ‚îî‚îÄ‚îÄ TRANEN_g19_transformer.py

```

Cada dataset publicado en `data` (resultado del proceso ETL) tiene una correspondencia con uno o m√°s *transformers* aqu√≠. Un dataset de `data` (por ejemplo, `matriz_prim_mundo_historic_larga.csv` en [`data`](https://github.com/argendatafundar/data/blob/main/TRANEN/matriz_prim_mundo_historic_larga.csv)) es el "insumo" para un *transformer* (como `TRANEN_g01_transformer.py` en [`transformers`](https://github.com/argendatafundar/transformers/blob/main/TRANEN/TRANEN_g01_transformer.py). Esta equivalencia est√° documentada en un archivo `mappings.json` dentro de cada subdirectorio de t√≥pico en este repositorio.

Un ejemplo de c√≥mo opera un *transformer* es el `TRANEN_g01_transformer.py`, que toma un *DataFrame* y aplica una serie de transformaciones usando funciones de `data-transformers` (como `query`, `rename_cols` y `sort_values`) para preparar los datos para la visualizaci√≥n final. Esto asegura que los datos sean presentados de forma √≥ptima y coherente en la web.\
\
Python

``` python
# Extracto del c√≥digo de TRANEN_g01_transformer.py 


from pandas import DataFrame
from data_transformers import chain, transformer


#  DEFINITIONS_START
@transformer.convert
def query(df: DataFrame, condition: str):
    df = df.query(condition)    
    return df

@transformer.convert
def rename_cols(df: DataFrame, map):
    df = df.rename(columns=map)
    return df

@transformer.convert
def sort_values(df: DataFrame, how: str, by: list):
    if how not in ['ascending', 'descending']:
        raise ValueError('how must be either "ascending" or "descending"')
    return df.sort_values(by=by, ascending=how == 'ascending')
#  DEFINITIONS_END


#  PIPELINE_START
pipeline = chain(
query(condition='tipo_energia != "Total"'),
    rename_cols(map={'tipo_energia': 'indicador', 'valor_en_twh': 'valor'}),
    sort_values(how='ascending', by=['anio', 'indicador'])
)
#  PIPELINE_END


#  start()
#  RangeIndex: 836 entries, 0 to 835
#  Data columns (total 4 columns):
#   #   Column        Non-Null Count  Dtype  
#  ---  ------        --------------  -----  
#   0   anio          836 non-null    int64  
#   1   tipo_energia  836 non-null    object 
#   2   valor_en_twh  836 non-null    float64
#   3   porcentaje    836 non-null    float64
#  
#  |    |   anio | tipo_energia     |   valor_en_twh |   porcentaje |
#  |---:|-------:|:-----------------|---------------:|-------------:|
#  |  0 |   1800 | Otras renovables |              0 |            0 |
#  
#  ------------------------------
#  
#  query(condition='tipo_energia != "Total"')
#  Index: 760 entries, 0 to 759
#  Data columns (total 4 columns):
#   #   Column        Non-Null Count  Dtype  
#  ---  ------        --------------  -----  
#   0   anio          760 non-null    int64  
#   1   tipo_energia  760 non-null    object 
#   2   valor_en_twh  760 non-null    float64
#   3   porcentaje    760 non-null    float64
#  
#  |    |   anio | tipo_energia     |   valor_en_twh |   porcentaje |
#  |---:|-------:|:-----------------|---------------:|-------------:|
#  |  0 |   1800 | Otras renovables |              0 |            0 |
#  
#  ------------------------------
#  
#  rename_cols(map={'tipo_energia': 'indicador', 'valor_en_twh': 'valor'})
#  Index: 760 entries, 0 to 759
#  Data columns (total 4 columns):
#   #   Column      Non-Null Count  Dtype  
#  ---  ------      --------------  -----  
#   0   anio        760 non-null    int64  
#   1   indicador   760 non-null    object 
#   2   valor       760 non-null    float64
#   3   porcentaje  760 non-null    float64
#  
#  |    |   anio | indicador        |   valor |   porcentaje |
#  |---:|-------:|:-----------------|--------:|-------------:|
#  |  0 |   1800 | Otras renovables |       0 |            0 |
#  
#  ------------------------------
#  
#  sort_values(how='ascending', by=['anio', 'indicador'])
#  Index: 760 entries, 76 to 227
#  Data columns (total 4 columns):
#   #   Column      Non-Null Count  Dtype  
#  ---  ------      --------------  -----  
#   0   anio        760 non-null    int64  
#   1   indicador   760 non-null    object 
#   2   valor       760 non-null    float64
#   3   porcentaje  760 non-null    float64
#  
#  |    |   anio | indicador       |   valor |   porcentaje |
#  |---:|-------:|:----------------|--------:|-------------:|
#  | 76 |   1800 | Biocombustibles |       0 |            0 |
#  
#  ------------------------------
#  


```

Este proceso en dos etapas (primero ETL, luego transformaci√≥n para *Frontend*) asegura la **calidad del dato base** y al mismo tiempo la **flexibilidad y eficiencia** en la **presentaci√≥n visual** de la informaci√≥n.\
\
--------\

{{< video http://149.50.137.164:2147/static/argendata/argendata-historico.mp4 >}}

\
Hasta ac√° un resumen de lo que fue el primer a√±o, centrado en **el camino de los datos.** En pr√≥ximas publicaciones, espero con *blogueros* inivtados, avanzaremos con m√°s detalle sobre algunos de los procesos, con especial atenci√≥n al trabajo dedicado a la visualizaci√≥n. \
\
Hasta la pr√≥xima y feliz cumple a nosotros =)\
